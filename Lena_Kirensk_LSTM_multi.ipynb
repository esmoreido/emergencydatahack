{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.layers import LSTM, Dense, Masking\n",
    "from tensorflow.keras import callbacks as cb\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "import tensorflow as tf\n",
    "from hydro_helpers.scoring import render_score\n",
    "from hydro_helpers.reporting import cv_report\n",
    "from hydro_helpers._utils import _nse as NSE\n",
    "from hydro_helpers._utils import _rmse as RMSE\n",
    "mpl.rcParams['figure.figsize'] = (20, 10)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "tf.random.set_seed(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12207, 211)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stage_max_3019</th>\n",
       "      <th>stage_max_3021</th>\n",
       "      <th>stage_max_3024</th>\n",
       "      <th>stage_max_3027</th>\n",
       "      <th>stage_max_3028</th>\n",
       "      <th>stage_max_3029</th>\n",
       "      <th>stage_max_3030</th>\n",
       "      <th>stage_max_3031</th>\n",
       "      <th>stage_max_3032</th>\n",
       "      <th>stage_max_3035</th>\n",
       "      <th>...</th>\n",
       "      <th>prec_30372</th>\n",
       "      <th>prec_30385</th>\n",
       "      <th>prec_30393</th>\n",
       "      <th>prec_30433</th>\n",
       "      <th>prec_30471</th>\n",
       "      <th>prec_30493</th>\n",
       "      <th>prec_31004</th>\n",
       "      <th>prec_31026</th>\n",
       "      <th>prec_31102</th>\n",
       "      <th>prec_31137</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1985-01-01</th>\n",
       "      <td>-23.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>51</td>\n",
       "      <td>126.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>143</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985-01-02</th>\n",
       "      <td>-23.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>49</td>\n",
       "      <td>122.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>141</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985-01-03</th>\n",
       "      <td>-23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>47</td>\n",
       "      <td>120.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>140</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985-01-04</th>\n",
       "      <td>-24.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>45</td>\n",
       "      <td>119.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>139</td>\n",
       "      <td>55</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985-01-05</th>\n",
       "      <td>-24.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>43</td>\n",
       "      <td>119.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>135</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 211 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            stage_max_3019  stage_max_3021  stage_max_3024  stage_max_3027  \\\n",
       "date                                                                         \n",
       "1985-01-01           -23.0           103.0           106.0            25.0   \n",
       "1985-01-02           -23.0           103.0           106.0            23.0   \n",
       "1985-01-03           -23.0           102.0           106.0            21.0   \n",
       "1985-01-04           -24.0           102.0           106.0            19.0   \n",
       "1985-01-05           -24.0           102.0           106.0            17.0   \n",
       "\n",
       "            stage_max_3028  stage_max_3029  stage_max_3030  stage_max_3031  \\\n",
       "date                                                                         \n",
       "1985-01-01           258.0              51           126.0           152.0   \n",
       "1985-01-02           258.0              49           122.0           150.0   \n",
       "1985-01-03           255.0              47           120.0           147.0   \n",
       "1985-01-04           252.0              45           119.0           146.0   \n",
       "1985-01-05           251.0              43           119.0           145.0   \n",
       "\n",
       "            stage_max_3032  stage_max_3035  ...  prec_30372  prec_30385  \\\n",
       "date                                        ...                           \n",
       "1985-01-01             143              59  ...         0.0         0.0   \n",
       "1985-01-02             141              58  ...         0.0         0.0   \n",
       "1985-01-03             140              57  ...         0.0         0.0   \n",
       "1985-01-04             139              55  ...         0.0         0.0   \n",
       "1985-01-05             135              53  ...         0.0         0.0   \n",
       "\n",
       "            prec_30393  prec_30433  prec_30471  prec_30493  prec_31004  \\\n",
       "date                                                                     \n",
       "1985-01-01         0.0         0.0         0.0         0.0         0.4   \n",
       "1985-01-02         0.0         0.9         0.0         0.0         0.5   \n",
       "1985-01-03         0.0         0.0         0.0         0.0         0.6   \n",
       "1985-01-04         0.6         0.3         0.0         0.2         3.0   \n",
       "1985-01-05         0.4         0.0         0.0         0.3         0.6   \n",
       "\n",
       "            prec_31026  prec_31102  prec_31137  \n",
       "date                                            \n",
       "1985-01-01         0.0         0.2         0.0  \n",
       "1985-01-02         0.7         0.0         0.7  \n",
       "1985-01-03         1.6         0.0         0.5  \n",
       "1985-01-04         0.2         0.3         0.3  \n",
       "1985-01-05         0.0         0.2         1.8  \n",
       "\n",
       "[5 rows x 211 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "river = 'lena'\n",
    "df = pd.read_csv('data/lena/train_df.txt', index_col='date')\n",
    "print(df.shape)\n",
    "df.index = pd.DatetimeIndex(df.index)\n",
    "# print(df.mean(axis=0))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12207, 192)\n",
      "stage_max_3019        0\n",
      "stage_max_3021        0\n",
      "stage_max_3024        0\n",
      "stage_max_3027        0\n",
      "stage_max_3028        0\n",
      "stage_max_3029        0\n",
      "stage_max_3030        0\n",
      "stage_max_3031        0\n",
      "stage_max_3032        0\n",
      "stage_max_3035        0\n",
      "stage_max_3036        0\n",
      "stage_max_3037        0\n",
      "stage_max_3038        0\n",
      "stage_max_3041        0\n",
      "stage_max_3042        0\n",
      "stage_max_3045        0\n",
      "stage_max_3047        0\n",
      "stage_max_3050        0\n",
      "stage_max_3087        0\n",
      "stage_max_3106        0\n",
      "stage_max_3169        0\n",
      "stage_max_3180        0\n",
      "stage_max_3229        0\n",
      "stage_max_3230        0\n",
      "stage_max_3554        0\n",
      "stage_max_3555        0\n",
      "ice_thickness_3019    0\n",
      "ice_thickness_3021    0\n",
      "ice_thickness_3024    0\n",
      "ice_thickness_3027    0\n",
      "                     ..\n",
      "prec_24763            0\n",
      "prec_24817            0\n",
      "prec_24923            0\n",
      "prec_24933            0\n",
      "prec_24944            0\n",
      "prec_24951            0\n",
      "prec_24959            0\n",
      "prec_24966            0\n",
      "prec_24967            0\n",
      "prec_30028            0\n",
      "prec_30054            0\n",
      "prec_30069            0\n",
      "prec_30089            0\n",
      "prec_30219            0\n",
      "prec_30230            0\n",
      "prec_30252            0\n",
      "prec_30253            0\n",
      "prec_30328            0\n",
      "prec_30337            0\n",
      "prec_30356            0\n",
      "prec_30372            0\n",
      "prec_30385            0\n",
      "prec_30393            0\n",
      "prec_30433            0\n",
      "prec_30471            0\n",
      "prec_30493            0\n",
      "prec_31004            0\n",
      "prec_31026            0\n",
      "prec_31102            0\n",
      "prec_31137            0\n",
      "Length: 191, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# run once\n",
    "df = df.dropna(axis=0, how='all')\n",
    "df = df.dropna(axis=1, how='all')\n",
    "# print(df.isna().sum())\n",
    "print(df.shape)\n",
    "del df['stage_max_3048']\n",
    "df = df.apply(lambda x: x.fillna(x.mean()),axis=0)\n",
    "# print(df.isna().sum())\n",
    "df = df.apply(lambda x: x.fillna(0),axis=0)\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.plot(subplots=True, figsize=[20,20])\n",
    "# plt.show()\n",
    "corr = round(df.corr(), 2)\n",
    "# целевые гидропосты\n",
    "# rownames = [k for k in corr.columns[corr.columns.str.contains(\"3019|3027|3028|3029|3030|3035|3041|3045|3050|3230|3036\")].values]\n",
    "rownames = [f'stage_max_{i}' for i in [3019,3027,3028,3029,3030,3035,3041,3045,3050,3230,3036]]\n",
    "# позиция целевых гидропостов\n",
    "# positions = [i for i, x in enumerate(corr.columns.str.contains(\"3019|3027|3028|3029|3030|3035|3041|3045|3050|3230|3036]\")) if x]\n",
    "# print(positions)\n",
    "corr.to_excel('results/lena_kirensk_corr.xlsx')\n",
    "corr.loc[rownames, :].transpose().style.background_gradient(cmap='coolwarm')\n",
    "# corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_data(dataset, target, start_index, end_index, history_size,\n",
    "                      target_size, step, single_step=False):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    start_index = start_index + history_size\n",
    "    if end_index is None:\n",
    "        end_index = len(dataset) - target_size\n",
    "\n",
    "    for i in range(start_index, end_index):\n",
    "        indices = range(i-history_size, i, step)\n",
    "        data.append(dataset[indices])\n",
    "\n",
    "        if single_step:\n",
    "            labels.append(target[i+target_size])\n",
    "        else:\n",
    "            labels.append(target[i:i+target_size])\n",
    "        \n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "\n",
    "def make_dataset(df, frac, target_label):\n",
    "    test_size = len(df) - int(len(df) * frac)\n",
    "    print('Train: ', test_size)\n",
    "    print('Test: ', len(df) - test_size)\n",
    "    dataset = df.values\n",
    "    data_mean = np.nanmean(dataset[:test_size], axis=0)\n",
    "    data_std = np.nanstd(dataset[:test_size], axis=0)\n",
    "    print(dataset[:test_size].shape)\n",
    "#     print(np.round(data_mean, 3), np.round(data_std, 2))\n",
    "    dataset = (dataset-data_mean)/data_std\n",
    "#     print(dataset[:,df.columns.get_loc(target_label)])\n",
    "    # shaping training and test dataset to chunks\n",
    "    x_train_multi, y_train_multi = multivariate_data(dataset[:, :], dataset[:, df.columns.get_loc(target_label)], len(dataset) - test_size,\n",
    "                                                     None, past_history,\n",
    "                                                     future_target, STEP)\n",
    "    x_val_multi, y_val_multi = multivariate_data(dataset[:, :], dataset[:, df.columns.get_loc(target_label)],\n",
    "                                                 0, int(len(df) * frac), past_history,\n",
    "                                                 future_target, STEP)\n",
    "    print('\\n Input training data shape:')\n",
    "    print(x_train_multi.shape[-2:], y_train_multi.shape[-2:])\n",
    "    print('\\n Input test data shape:')\n",
    "    print(x_val_multi.shape[-2:], y_val_multi.shape[-2:])\n",
    "#     print('\\n Single step history:')\n",
    "#     print(x_train_multi[0])\n",
    "#     print('\\n Single step target:')\n",
    "#     print(y_train_multi[0])\n",
    "    return x_train_multi, y_train_multi, x_val_multi, y_val_multi, data_mean, data_std\n",
    "\n",
    "\n",
    "def model_build(df, target_label):\n",
    "    print(target_label)\n",
    "    x_train_multi, y_train_multi, x_val_multi, y_val_multi, data_mean, data_std = make_dataset(df, 0.2)\n",
    "    \n",
    "    # create train and test data from chunks\n",
    "    train_data_multi = tf.data.Dataset.from_tensor_slices((x_train_multi, y_train_multi))\n",
    "    val_data_multi = tf.data.Dataset.from_tensor_slices((x_val_multi, y_val_multi))\n",
    "\n",
    "    # training and test data shuffling\n",
    "    train_data_multi = train_data_multi.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "    val_data_multi = val_data_multi.batch(BATCH_SIZE).repeat()\n",
    "\n",
    "    multi_step_model = tf.keras.models.Sequential()\n",
    "    multi_step_model.add(tf.keras.layers.LSTM(50,\n",
    "                                              return_sequences=False,\n",
    "                                              input_shape=x_train_multi.shape[-2:]))\n",
    "    multi_step_model.add(tf.keras.layers.Dense(7))\n",
    "\n",
    "    multi_step_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, \n",
    "                                                                beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "                                                                name='Adam'), \n",
    "                             loss='mse')\n",
    "\n",
    "    model_callbacks = [cb.EarlyStopping(patience=10), \n",
    "                              cb.ModelCheckpoint(filepath=f\"output/\"+ river + \"_\" + target_label + \"_LSTM.h5\", save_best_only=True)]\n",
    "    multi_step_history = multi_step_model.fit(train_data_multi, epochs=EPOCHS,\n",
    "                                          steps_per_epoch=EVALUATION_INTERVAL,\n",
    "                                          validation_data=val_data_multi,\n",
    "                                          validation_steps=10,\n",
    "                                          callbacks=model_callbacks)\n",
    "    loss = multi_step_history.history['loss']\n",
    "    val_loss = multi_step_history.history['val_loss']\n",
    "    epochs = range(len(loss)) \n",
    "    plt.figure(figsize=[10,10])\n",
    "    plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stage_max_3019', 'stage_max_3027', 'stage_max_3028', 'stage_max_3029', 'stage_max_3030', 'stage_max_3035', 'stage_max_3041', 'stage_max_3045', 'stage_max_3050', 'stage_max_3230', 'stage_max_3036']\n"
     ]
    }
   ],
   "source": [
    "# define train/test split\n",
    "target_labels = [f'stage_max_{i}' for i in [3019,3027,3028,3029,3030,3035,3041,3045,3050,3230,3036]]\n",
    "print(target_labels)\n",
    "# lookback parameters\n",
    "past_history = 60 # how many instances a model sees for training, in compliance with other models' input\n",
    "future_target = 7 # how many instances form a prediction step\n",
    "STEP = 1 # step size - 1 for daily data\n",
    "BATCH_SIZE = 30 \n",
    "BUFFER_SIZE = 1000\n",
    "EVALUATION_INTERVAL = len(df.values)/BATCH_SIZE # what data model sees for training\n",
    "EPOCHS = 100 # how many times a model sees the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run model training and saving\n",
    "for l in target_labels:\n",
    "    model_build(df, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12361, 191)\n",
      "DatetimeIndex(['1985-01-01', '1985-01-02', '1985-01-03', '1985-01-04',\n",
      "               '1985-01-05', '1985-01-06', '1985-01-07', '1985-01-08',\n",
      "               '1985-01-09', '1985-01-10',\n",
      "               ...\n",
      "               '2019-12-22', '2019-12-23', '2019-12-24', '2019-12-25',\n",
      "               '2019-12-26', '2019-12-27', '2019-12-28', '2019-12-29',\n",
      "               '2019-12-30', '2019-12-31'],\n",
      "              dtype='datetime64[ns]', length=12783, freq='D')\n"
     ]
    }
   ],
   "source": [
    "# new data\n",
    "new_df = pd.read_csv('data/lena/df_input_cp3.txt', index_col='date')\n",
    "new_df.index = pd.DatetimeIndex(new_df.index)\n",
    "new_df = new_df.dropna(axis=1, how='all')\n",
    "del new_df['stage_max_3048']\n",
    "print(new_df.shape)\n",
    "new_df = new_df.apply(lambda x: x.fillna(x.mean()),axis=0)\n",
    "new_df = new_df.apply(lambda x: x.fillna(0),axis=0)\n",
    "# print(new_df.isna().sum())\n",
    "ondates = pd.date_range(start=min(new_df.index), end=max(new_df.index), freq='D')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stage_max_3019\n",
      "Train:  12238\n",
      "Test:  123\n",
      "(12238, 191)\n",
      "\n",
      " Input training data shape:\n",
      "(60, 191) (12171, 7)\n",
      "\n",
      " Input test data shape:\n",
      "(60, 191) (63, 7)\n",
      "stage_max_3027\n",
      "Train:  12238\n",
      "Test:  123\n",
      "(12238, 191)\n",
      "\n",
      " Input training data shape:\n",
      "(60, 191) (12171, 7)\n",
      "\n",
      " Input test data shape:\n",
      "(60, 191) (63, 7)\n",
      "stage_max_3028\n",
      "Train:  12238\n",
      "Test:  123\n",
      "(12238, 191)\n",
      "\n",
      " Input training data shape:\n",
      "(60, 191) (12171, 7)\n",
      "\n",
      " Input test data shape:\n",
      "(60, 191) (63, 7)\n",
      "stage_max_3029\n",
      "Train:  12238\n",
      "Test:  123\n",
      "(12238, 191)\n",
      "\n",
      " Input training data shape:\n",
      "(60, 191) (12171, 7)\n",
      "\n",
      " Input test data shape:\n",
      "(60, 191) (63, 7)\n",
      "stage_max_3030\n",
      "Train:  12238\n",
      "Test:  123\n",
      "(12238, 191)\n",
      "\n",
      " Input training data shape:\n",
      "(60, 191) (12171, 7)\n",
      "\n",
      " Input test data shape:\n",
      "(60, 191) (63, 7)\n",
      "stage_max_3035\n",
      "Train:  12238\n",
      "Test:  123\n",
      "(12238, 191)\n",
      "\n",
      " Input training data shape:\n",
      "(60, 191) (12171, 7)\n",
      "\n",
      " Input test data shape:\n",
      "(60, 191) (63, 7)\n",
      "stage_max_3041\n",
      "Train:  12238\n",
      "Test:  123\n",
      "(12238, 191)\n",
      "\n",
      " Input training data shape:\n",
      "(60, 191) (12171, 7)\n",
      "\n",
      " Input test data shape:\n",
      "(60, 191) (63, 7)\n",
      "stage_max_3045\n",
      "Train:  12238\n",
      "Test:  123\n",
      "(12238, 191)\n",
      "\n",
      " Input training data shape:\n",
      "(60, 191) (12171, 7)\n",
      "\n",
      " Input test data shape:\n",
      "(60, 191) (63, 7)\n",
      "stage_max_3050\n",
      "Train:  12238\n",
      "Test:  123\n",
      "(12238, 191)\n",
      "\n",
      " Input training data shape:\n",
      "(60, 191) (12171, 7)\n",
      "\n",
      " Input test data shape:\n",
      "(60, 191) (63, 7)\n",
      "stage_max_3230\n",
      "Train:  12238\n",
      "Test:  123\n",
      "(12238, 191)\n",
      "\n",
      " Input training data shape:\n",
      "(60, 191) (12171, 7)\n",
      "\n",
      " Input test data shape:\n",
      "(60, 191) (63, 7)\n",
      "stage_max_3036\n",
      "Train:  12238\n",
      "Test:  123\n",
      "(12238, 191)\n",
      "\n",
      " Input training data shape:\n",
      "(60, 191) (12171, 7)\n",
      "\n",
      " Input test data shape:\n",
      "(60, 191) (63, 7)\n",
      "                   0              1              2              3  \\\n",
      "count  133881.000000  133881.000000  133881.000000  133881.000000   \n",
      "mean      198.551163     197.254456     198.684433     201.586014   \n",
      "std       236.708054     233.641556     234.227219     233.146179   \n",
      "min      -435.701263    -451.142151    -424.883667    -413.113831   \n",
      "25%        53.497116      53.234612      54.648590      56.336426   \n",
      "50%       162.702591     160.631592     161.215027     165.585419   \n",
      "75%       284.191589     281.283966     282.367706     288.118988   \n",
      "max      1518.088867    1520.941162    1486.361450    1491.720947   \n",
      "\n",
      "                   4              5              6  \n",
      "count  133881.000000  133881.000000  133881.000000  \n",
      "mean      200.421036     200.897476     198.506424  \n",
      "std       233.087143     228.736710     229.568390  \n",
      "min      -442.149445    -433.998260    -450.699402  \n",
      "25%        55.334412      57.841545      56.731461  \n",
      "50%       164.189316     166.190613     163.598267  \n",
      "75%       284.725037     283.519470     283.867676  \n",
      "max      1468.654297    1468.512451    1466.695068  \n"
     ]
    }
   ],
   "source": [
    "# load trained model for time saving\n",
    "output_df = pd.DataFrame() # df for all gauges' predictions\n",
    "# gauges loop\n",
    "for lab in [f'stage_max_{i}' for i in [3019,3027,3028,3029,3030,3035,3041,3045,3050,3230,3036]]:\n",
    "    print(lab)\n",
    "    # shape new data\n",
    "    val_frac = 0.01\n",
    "    nt, nv, vt, vv, dm, dstd = make_dataset(new_df, val_frac, lab)\n",
    "#     print(nt.shape, nv.shape, vt.shape, vv.shape)\n",
    "    # load model\n",
    "    multi_step_model = load_model(f\"output/lena_\" + lab + \"_LSTM.h5\")\n",
    "#     print(multi_step_model.summary())\n",
    "#     print('Multi-step model prediction shape:')\n",
    "#     print(multi_step_model.predict(nt).shape)\n",
    "    # predict\n",
    "    pred = pd.DataFrame(multi_step_model.predict(nt) * dstd[df.columns.get_loc(lab)] + dm[df.columns.get_loc(lab)])\n",
    "#     print(pred.head())\n",
    "#     for i in range(future_target):\n",
    "#         pred[i] = pred[i].shift(i)\n",
    "#     pred.columns = [f'pred_{i}' for i in range(1, future_target + 1)]\n",
    "    # get time index\n",
    "    start_index = len(new_df) - (len(new_df) - int(len(new_df) * val_frac)) + past_history + future_target\n",
    "    pred['date'] = new_df[start_index:].index.values\n",
    "    \n",
    "    # 7-day forecast\n",
    "#     forecast = pred.melt(id_vars = 'date_issued', var_name = 'horizon')\n",
    "#     print(forecast.head())\n",
    "#     forecast['date_valid'] = forecast['date_issued'] + pd.to_timedelta(forecast['horizon'].astype(int), unit='day')\n",
    "#     forecast = forecast.sort_values(by=['date_issued', 'horizon'])\n",
    "#     forecast.reset_index()\n",
    "#     print(forecast.head(25))\n",
    "    \n",
    "    # get observations\n",
    "#     pred['fact'] = new_df[start_index:][lab]\n",
    "    \n",
    "    # plot    \n",
    "#     fig, ax = plt.subplots()\n",
    "#     subdf = pred['2013-04-01':'2013-06-30']\n",
    "#     subdf.plot(ax=ax)\n",
    "#     subdf['fact'].plot(ax=ax, lw=5)\n",
    "#     subdf.diff().plot()\n",
    "#     subdf['fact'].diff().plot(lw=5)\n",
    "#     plt.show()\n",
    "#     subdf.head(7)\n",
    "    pred['index'] = lab\n",
    "    output_df = output_df.append(pred)\n",
    "print(output_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>date</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>195.587860</td>\n",
       "      <td>185.976761</td>\n",
       "      <td>179.276459</td>\n",
       "      <td>182.952957</td>\n",
       "      <td>174.098526</td>\n",
       "      <td>159.069214</td>\n",
       "      <td>137.992126</td>\n",
       "      <td>1985-07-10</td>\n",
       "      <td>3019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>187.247101</td>\n",
       "      <td>173.931778</td>\n",
       "      <td>164.207977</td>\n",
       "      <td>165.996307</td>\n",
       "      <td>156.010864</td>\n",
       "      <td>140.996155</td>\n",
       "      <td>121.002525</td>\n",
       "      <td>1985-07-11</td>\n",
       "      <td>3019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>168.443100</td>\n",
       "      <td>156.803665</td>\n",
       "      <td>146.201691</td>\n",
       "      <td>146.987610</td>\n",
       "      <td>139.482758</td>\n",
       "      <td>123.754486</td>\n",
       "      <td>105.276970</td>\n",
       "      <td>1985-07-12</td>\n",
       "      <td>3019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>160.241333</td>\n",
       "      <td>147.517334</td>\n",
       "      <td>135.260162</td>\n",
       "      <td>136.399902</td>\n",
       "      <td>131.309906</td>\n",
       "      <td>117.281456</td>\n",
       "      <td>103.222618</td>\n",
       "      <td>1985-07-13</td>\n",
       "      <td>3019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142.389099</td>\n",
       "      <td>132.688675</td>\n",
       "      <td>125.550392</td>\n",
       "      <td>132.286407</td>\n",
       "      <td>133.480270</td>\n",
       "      <td>124.539215</td>\n",
       "      <td>114.573914</td>\n",
       "      <td>1985-07-14</td>\n",
       "      <td>3019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>113.926498</td>\n",
       "      <td>112.758057</td>\n",
       "      <td>111.733566</td>\n",
       "      <td>116.487686</td>\n",
       "      <td>111.656586</td>\n",
       "      <td>102.422043</td>\n",
       "      <td>88.550079</td>\n",
       "      <td>1985-07-15</td>\n",
       "      <td>3019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>112.534378</td>\n",
       "      <td>107.726677</td>\n",
       "      <td>104.368118</td>\n",
       "      <td>108.001282</td>\n",
       "      <td>109.419922</td>\n",
       "      <td>105.342888</td>\n",
       "      <td>98.924240</td>\n",
       "      <td>1985-07-16</td>\n",
       "      <td>3019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>116.470993</td>\n",
       "      <td>110.143631</td>\n",
       "      <td>103.238663</td>\n",
       "      <td>101.764801</td>\n",
       "      <td>107.399681</td>\n",
       "      <td>99.971146</td>\n",
       "      <td>97.193527</td>\n",
       "      <td>1985-07-17</td>\n",
       "      <td>3019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>89.000702</td>\n",
       "      <td>101.676331</td>\n",
       "      <td>105.514816</td>\n",
       "      <td>102.921867</td>\n",
       "      <td>108.578064</td>\n",
       "      <td>99.181610</td>\n",
       "      <td>90.747696</td>\n",
       "      <td>1985-07-18</td>\n",
       "      <td>3019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>91.029594</td>\n",
       "      <td>85.234329</td>\n",
       "      <td>82.614563</td>\n",
       "      <td>73.660126</td>\n",
       "      <td>75.546692</td>\n",
       "      <td>66.307106</td>\n",
       "      <td>68.482674</td>\n",
       "      <td>1985-07-19</td>\n",
       "      <td>3019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0           1           2           3           4           5  \\\n",
       "0  195.587860  185.976761  179.276459  182.952957  174.098526  159.069214   \n",
       "1  187.247101  173.931778  164.207977  165.996307  156.010864  140.996155   \n",
       "2  168.443100  156.803665  146.201691  146.987610  139.482758  123.754486   \n",
       "3  160.241333  147.517334  135.260162  136.399902  131.309906  117.281456   \n",
       "4  142.389099  132.688675  125.550392  132.286407  133.480270  124.539215   \n",
       "5  113.926498  112.758057  111.733566  116.487686  111.656586  102.422043   \n",
       "6  112.534378  107.726677  104.368118  108.001282  109.419922  105.342888   \n",
       "7  116.470993  110.143631  103.238663  101.764801  107.399681   99.971146   \n",
       "8   89.000702  101.676331  105.514816  102.921867  108.578064   99.181610   \n",
       "9   91.029594   85.234329   82.614563   73.660126   75.546692   66.307106   \n",
       "\n",
       "            6       date  index  \n",
       "0  137.992126 1985-07-10   3019  \n",
       "1  121.002525 1985-07-11   3019  \n",
       "2  105.276970 1985-07-12   3019  \n",
       "3  103.222618 1985-07-13   3019  \n",
       "4  114.573914 1985-07-14   3019  \n",
       "5   88.550079 1985-07-15   3019  \n",
       "6   98.924240 1985-07-16   3019  \n",
       "7   97.193527 1985-07-17   3019  \n",
       "8   90.747696 1985-07-18   3019  \n",
       "9   68.482674 1985-07-19   3019  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output_df['index'] = output_df['index'].str[-4:].astype(int)\n",
    "output_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  station_id  month  day       date  delta_stage_max\n",
      "0  1993        3019      4  111 1993-04-21              NaN\n",
      "1  1993        3019      4  112 1993-04-22              NaN\n",
      "2  1993        3019      4  113 1993-04-23              NaN\n",
      "3  1993        3019      4  114 1993-04-24              NaN\n",
      "4  1993        3019      4  115 1993-04-25              NaN\n",
      "   year  station_id  month  day       date  delta_stage_max   0   1   2   3  \\\n",
      "0  1993        3019      4  111 1993-04-21              NaN NaN NaN NaN NaN   \n",
      "1  1993        3019      4  112 1993-04-22              NaN NaN NaN NaN NaN   \n",
      "2  1993        3019      4  113 1993-04-23              NaN NaN NaN NaN NaN   \n",
      "3  1993        3019      4  114 1993-04-24              NaN NaN NaN NaN NaN   \n",
      "4  1993        3019      4  115 1993-04-25              NaN NaN NaN NaN NaN   \n",
      "5  1993        3019      4  116 1993-04-26              NaN NaN NaN NaN NaN   \n",
      "6  1993        3019      4  117 1993-04-27              NaN NaN NaN NaN NaN   \n",
      "7  1997        3019      4  111 1997-04-21              NaN NaN NaN NaN NaN   \n",
      "8  1997        3019      4  112 1997-04-22              NaN NaN NaN NaN NaN   \n",
      "9  1997        3019      4  113 1997-04-23              NaN NaN NaN NaN NaN   \n",
      "\n",
      "    4   5   6  index  \n",
      "0 NaN NaN NaN    NaN  \n",
      "1 NaN NaN NaN    NaN  \n",
      "2 NaN NaN NaN    NaN  \n",
      "3 NaN NaN NaN    NaN  \n",
      "4 NaN NaN NaN    NaN  \n",
      "5 NaN NaN NaN    NaN  \n",
      "6 NaN NaN NaN    NaN  \n",
      "7 NaN NaN NaN    NaN  \n",
      "8 NaN NaN NaN    NaN  \n",
      "9 NaN NaN NaN    NaN  \n"
     ]
    }
   ],
   "source": [
    "# extract test periods' predictions\n",
    "test_cp1 = pd.read_csv(r'data/lena/test_cp4.csv')\n",
    "test_cp1['date'] = pd.to_datetime(test_cp1['date'])\n",
    "print(test_cp1.head())\n",
    "solution_cp1 = pd.merge(test_cp1, output_df, how = 'left', left_on=['date', 'station_id'], right_on=['date', 'index'])\n",
    "print(solution_cp1.head(10))\n",
    "solution_cp1.to_excel('results/solcp1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
